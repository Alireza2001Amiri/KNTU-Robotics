% !TeX root=../main.tex

\chapter*{تحقیق دوم، تنسورها}

تنسورها تعمیمی از اسکالرها، بردارها و ماتریس‌ها هستند که امکان نمایش و تحلیل داده‌ها در ابعاد بالاتر را فراهم می‌کنند. آن‌ها در فیزیک، مهندسی و یادگیری ماشین کاربرد گسترده‌ای دارند. تنسورها را می‌توان به‌صورت آرایه‌های چندبعدی نمایش داد، به‌طوری که مرتبه آن‌ها تعداد شاخص‌های موردنیاز را مشخص می‌کند. برای مثال:
\begin{itemize}
	\item اسکالرها: $T$
	\item بردارها: $T_i$
	\item ماتریس‌ها: $T_{ij}$
	\item تنسورهای مرتبه بالاتر: $T_{ijk}$
\end{itemize}
یک تنسور مرتبه-$n$ قوانین تبدیل خاصی را تحت تغییر مختصات دنبال می‌کند:
\begin{equation}
	T'^{i_1 i_2 \dots i_n} = \sum_{j_1 j_2 \dots j_n} \Lambda^{i_1}_{j_1} \Lambda^{i_2}_{j_2} \dots \Lambda^{i_n}_{j_n} T^{j_1 j_2 \dots j_n}
\end{equation}
که در آن $\Lambda$ ماتریس تبدیل است.

ماتریس‌ها حالت خاصی از تنسورها هستند که در دو بعد تعریف می‌شوند. 
یکی از کاربردهای مهم تنسورها در فیزیک مواد است، جایی که تنسور تنش به‌صورت زیر تعریف می‌شود:
\begin{equation}
	\sigma_{ij} = \frac{\partial F_i}{\partial x_j}
\end{equation}
که در آن $F_i$ مؤلفه‌های نیرو و $x_j$ مختصات فضایی هستند. همچنین، در نظریه نسبیت عام، معادله میدان اینشتین به فرم زیر بیان می‌شود:
\begin{equation}
	G_{\mu\nu} + \Lambda g_{\mu\nu} = \frac{8\pi G}{c^4} T_{\mu\nu}
\end{equation}
که در آن $G_{\mu\nu}$ تنسور اینشتین و $T_{\mu\nu}$ تنسور انرژی-تکانه است.

تنسورها در یادگیری ماشین نیز نقش کلیدی دارند، به‌ویژه در شبکه‌های عصبی عمیق که داده‌ها به‌صورت آرایه‌های چندبعدی نمایش داده می‌شوند.



